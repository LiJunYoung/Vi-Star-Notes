# 电商软件环境安装

电商软件环境安装部署

# 一、环境准备

## 1安装docker

环境安装：

> yum -y install gcc-c++

第一步：安装必要的一些系统工具

> yum install -y yum-utils device-mapper-persistent-data lvm2

第二步：添加软件源信息

> yum-config-manager --add-repo [http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo](http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo "http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo")

第三步：更新并安装Docker-CE

> yum makecache fast
> yum -y install docker-ce

第四步：开启Docker服务

> service docker start
> systemctl enable docker

第五步：测试是否安装成功

> docker -v

第六步：配置镜像加速器

您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器

> sudo mkdir -p /etc/docker

新建daemon.json文件内容如下：

```bash
{
"registry-mirrors":["https://docker.mirrors.ustc.edu.cn","http://hubmirror.c.163.com"]
}
```

> sudo systemctl daemon-reload
> sudo systemctl restart docker

## 2安装mysql

已安装或能访问忽略

第一步：拉取镜像

> docker pull mysql:8.0.29

第二步：启动

> docker run --name gmalldocker\_mysql --restart=always -v /home/ljaer/mysql:/var/lib/mysql -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=root -d mysql:8.0.29

第三步：测试mysql

进入容器：

> docker exec -it sun\_mysql /bin/bash

登录mysql：

mysql -u root -p

root

如果顺利进入，安装成功

## 3安装rabbitmq

第一步：拉取镜像

> docker pull rabbitmq:3.9.11-management

第二步：启动

> docker run -d -p 5672:5672 -p 15672:15672 --restart=always --name rabbitmq  rabbitmq:3.9.11-management

第三步：安装延迟队列插件

1.  首先下载rabbitmq\_delayed\_message\_exchange-3.9.0.ez文件上传到RabbitMQ所在服务器，下载地址：[https://www.rabbitmq.com/community-plugins.html](https://www.rabbitmq.com/community-plugins.html "https://www.rabbitmq.com/community-plugins.html")
2.  切换到插件所在目录，执行 docker cp rabbitmq\_delayed\_message\_exchange-3.9.0.ez rabbitmq:/plugins 命令，将刚插件拷贝到容器内plugins目录下
3.  执行 docker exec -it rabbitmq /bin/bash 命令进入到容器内部，并 cd plugins 进入plugins目录
4.  执行 ls -l|grep delay  命令查看插件是否copy成功
5.  在容器内plugins目录下，执行 rabbitmq-plugins enable rabbitmq\_delayed\_message\_exchange  命令启用插件
6.  exit命令退出RabbitMQ容器内部，然后执行 docker restart rabbitmq 命令重启RabbitMQ容器

systemctl restart docker;

## 4安装redis

已安装或能访问忽略

第一步：拉取镜像

> docker pull redis:6.2.5

第二步：启动

> docker run --name=gmalldocker\_redis -d -p 6379:6379  --restart=always redis:6.2.5

## 5安装nacos

已安装或能访问忽略

第一步：拉取镜像

> docker pull nacos/nacos-server:1.4.1

第二步：启动

> docker run --env MODE=standalone --name gmalldocker\_nacos --restart=always -d -p 8848:8848 -e JVM\_XMS=512m -e JVM\_XMX=512m nacos/nacos-server:1.4.1

## 6安装sentinel

已安装或能访问忽略

第一步：拉取镜像

> docker pull bladex/sentinel-dashboard

第二步：启动

> docker run --name=gmalldocker\_sentinel-dashboard --restart=always -p 8858:8858 -d bladex/sentinel-dashboard:latest

## 7安装elasticsearch

已安装或能访问忽略

第一步：拉取镜像

> docker pull elasticsearch:7.8.0

第二步：启动

需要在宿主机建立：两个文件夹

> mkdir -p /mydata/elasticsearch/plugins

> mkdir -p /mydata/elasticsearch/data

授予权限

> chmod 777 /mydata/elasticsearch/data

执行

```纯文本
docker run -p 9200:9200 -p 9300:9300 --name gmalldocker_elasticsearch --restart=always \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms512m -Xmx512m" \
-v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \
-v /mydata/elasticsearch/conf:/usr/share/elasticsearch/conf \
-d elasticsearch:7.8.0
```

第三步：安装中文分词器

1.  下载elasticsearch-analysis-ik-7.8.0.zip
2.  上传到/mydata/elasticsearch/plugins 目录后，解压：unzip elasticsearch-analysis-ik-7.8.0.zip -d ik-analyzer
    **必须删除原来的压缩包elasticsearch-analysis-ik-7.8.0.zip**
3.  重启es：docker restart a24eb9941759

a24eb9941759：表示容器ID 运行时，需要改成自己的容器ID

## 8安装logstash/filebeat

安装logstash

第一步：拉取镜像

> docker pull logstash:7.8.0

第二步：需要提前在linux服务器上环境 /mydata/logstash/logstash.conf,内容如下

> mkdir -p /mydata/logstash

```json
input {
  tcp {
  mode => "server"
  host => "0.0.0.0"
  port => 5044
  codec => json_lines
  }
}
filter{
  
}
output {
  elasticsearch {
  hosts => "192.168.200.128:9200"
  index => "gmall-%{+YYYY.MM.dd}"
  }
}
```

第三步：创建容器

```纯文本
docker run --name gmalldocker_logstash -p 5044:5044 \
--restart=always \
--link gmalldocker_elasticsearch:es \
-v /mydata/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \
-d logstash:7.8.0
```

安装Filebeat

第一步：授权

chmod 777 -R /var/log/messages

第二步：启动日志收集器

```text
docker run -d \
  --name=filebeat \
  --restart=always \
  -v filebeat-conf:/usr/share/filebeat \
  -v /var/log/messages:/var/log/messages \
  --link 1833f6a65c2a:gmalldocker_elasticsearch \
  elastic/filebeat:7.8.0
  
  1833f6a65c2a: es容器的ID
```

第三步：修改配置文件：

```纯文本
进入到目录：
cd /var/lib/docker/volumes/filebeat-conf/_data
修改配置文件
vim filebeat.yml
内容如下
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/messages
filebeat.config:
  modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false

processors:
  - add_cloud_metadata: ~
  - add_docker_metadata: ~

output.elasticsearch:
  hosts: '192.168.200.128:9200'
  indices:
   - index: "filebeat-%{+yyyy.MM.dd}"
```

效果：以后虚拟机上的所有日志都会收集保存到es中，可以在kibana中进行检索。

![](image/image_mwMxZ-RKjU.png)

第四步： 创建可视化面板

![](image/image_7-ouQP6Atx.png)

![](image/image_2qUbFb3D3W.png)

![](image/image_7P_2GHOXD3.png)

![](image/image_EZd4xuwYEN.png)

在左侧菜单栏**点击Discover** 选项，就可以看到filebeat 收集的数据了。

![](image/image_kCYE3abvrJ.png)

![](image/image_kCYE3abvrJ.png)

## 9安装kibana

第一步：拉取镜像

docker pull kibana:7.8.0

第二步：启动

> docker run --name gmalldocker\_kibana --restart=always -e ELASTICSEARCH\_URL=[http://192.168.200.128:9200](http://192.168.200.128:9200 "http://192.168.200.128:9200") -p 5601:5601 -d kibana:7.8.0

进入容器修改：

> docker exec -it gmalldocker\_kibana  /bin/bash

> cd config
> vi kibana.yml

```yaml
elasticsearch.hosts: [ "http://192.168.200.128:9200" ]
```

> docker restart gmalldocker\_kibana      重启kibana ！

测试：在Kibana开发工具中，测试安装分词词库是否可以使用！

```json
GET  /_analyze
{
  "analyzer": "ik_smart", 
  "text":     "我是中国人"
}
```

## 10安装zipkin

第一步：拉取镜像

> docker pull openzipkin/zipkin

第二步：启动

> docker run --name zipkin --restart=always -d -p 9411:9411 openzipkin/zipkin

## 11安装minio

已安装或能访问忽略

第一步：拉取镜像

> docker pull minio/minio

第二步：启动

```纯文本
docker run \
-p 9000:9000 \
-p 9001:9001 \
--name=gmalldocker_minio \
-d --restart=always \
-e "MINIO_ROOT_USER=admin" \
-e "MINIO_ROOT_PASSWORD=admin123456" \
-v /home/data:/data \
-v /home/config:/root/.minio \
minio/minio server /data --console-address ":9001"
```

浏览器访问：[http://IP:9001/minio/login，登录使用自定义账户密码admin/admin123456登录](http://IP:9001/minio/login，登录使用自定义账户密码admin/admin123456登录 "http://IP:9001/minio/login，登录使用自定义账户密码admin/admin123456登录")

**注意**：文件上传时，需要调整一下linux 服务器的时间与windows 时间一致！

> 第一步：安装ntp服务
> yum -y install ntp
> 第二步：开启开机启动服务
> systemctl enable ntpd
> 第三步：启动服务
> systemctl start ntpd
> 第四步：更改时区
> timedatectl set-timezone Asia/Shanghai
> 第五步：启用ntp同步
> timedatectl set-ntp yes
> 第六步：同步时间
> ntpq -p

## 12安装在线Yapi 服务器

拉取镜像

> docker pull mongo:4.2.5

启动mongo

> docker run -d --name mongo-yapi  --restart=always -p 27017:27017 -v /mydata/mongodb:/data/db  mongo:4.2.5

获取Yapi 镜像

> docker pull registry.cn-hangzhou.aliyuncs.com/anoy/yapi

初始化Yapi 数据库索引以及管理员账号

> docker run -it --rm  --link mongo-yapi:mongo  --entrypoint npm  --workdir /api/vendors  registry.cn-hangzhou.aliyuncs.com/anoy/yapi  run install-server

![](image/image-20221128104310609_LxQ7RVSyLq.png)

启动Yapi 服务

> docker run -d  --name yapi  --restart=always --link mongo-yapi:mongo  --workdir /api/vendors  -p 3000:3000  registry.cn-hangzhou.aliyuncs.com/anoy/yapi  server/app.js

使用Yapi [http://192.168.200.128:3000](http://192.168.200.128:3000 "http://192.168.200.128:3000") 登录账号 [admin@admin.com](mailto:admin@admin.com "admin@admin.com")，密码 ymfe.org

# 注意：

停止所有的容器

> docker stop \$(docker ps -aq)

删除所有的容器

> docker rm \$(docker ps -aq)

\#删除所有的镜像

> docker rmi \$(docker images -q)
